{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1-final"
    },
    "colab": {
      "name": "Classification_no_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylZTgcgCa_EH",
        "colab_type": "text"
      },
      "source": [
        "# Twitter account classification, no NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAMuFR1F54Rt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OcWjvq1U2jT",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMcPDtXZPnR7",
        "colab_type": "text"
      },
      "source": [
        "Read the csv files containing user data and inspect columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNcXpOCn54R-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tradicionalbot_us = pd.read_csv('datasets_full/traditional_spambots_1/users.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9WN-xsN54SP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "ce59cefb-96fd-4735-a536-1495798a3ce7"
      },
      "source": [
        "df_tradicionalbot_us.columns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'screen_name', 'statuses_count', 'followers_count',\n",
              "       'friends_count', 'favourites_count', 'listed_count', 'url', 'lang',\n",
              "       'time_zone', 'location', 'default_profile', 'default_profile_image',\n",
              "       'geo_enabled', 'profile_image_url', 'profile_banner_url',\n",
              "       'profile_use_background_image', 'profile_background_image_url_https',\n",
              "       'profile_text_color', 'profile_image_url_https',\n",
              "       'profile_sidebar_border_color', 'profile_background_tile',\n",
              "       'profile_sidebar_fill_color', 'profile_background_image_url',\n",
              "       'profile_background_color', 'profile_link_color', 'utc_offset',\n",
              "       'is_translator', 'follow_request_sent', 'protected', 'verified',\n",
              "       'notifications', 'description', 'contributors_enabled', 'following',\n",
              "       'created_at', 'timestamp', 'crawled_at', 'updated'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75EL7QED54Sc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_genuine_us = pd.read_csv('datasets_full/genuine_accounts.csv/users.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtHfX8wM54Sj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "837dad47-e535-4dae-98d3-66d111684854"
      },
      "source": [
        "df_genuine_us.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'screen_name', 'statuses_count', 'followers_count',\n",
              "       'friends_count', 'favourites_count', 'listed_count', 'url', 'lang',\n",
              "       'time_zone', 'location', 'default_profile', 'default_profile_image',\n",
              "       'geo_enabled', 'profile_image_url', 'profile_banner_url',\n",
              "       'profile_use_background_image', 'profile_background_image_url_https',\n",
              "       'profile_text_color', 'profile_image_url_https',\n",
              "       'profile_sidebar_border_color', 'profile_background_tile',\n",
              "       'profile_sidebar_fill_color', 'profile_background_image_url',\n",
              "       'profile_background_color', 'profile_link_color', 'utc_offset',\n",
              "       'is_translator', 'follow_request_sent', 'protected', 'verified',\n",
              "       'notifications', 'description', 'contributors_enabled', 'following',\n",
              "       'created_at', 'timestamp', 'crawled_at', 'updated', 'test_set_1',\n",
              "       'test_set_2'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nnkeseTP0SJ",
        "colab_type": "text"
      },
      "source": [
        "Drop unnecessary columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01opULCG54St",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_genuine_us = df_genuine_us.drop(['test_set_1','test_set_2'], axis=1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hin1wjRGQDcc",
        "colab_type": "text"
      },
      "source": [
        "Split train and test data for bots and human accounts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w1W-9_554S3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(df_tradicionalbot_us, np.ones(df_tradicionalbot_us['id'].unique().shape[0]), random_state=42)\n",
        "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(df_genuine_us, np.zeros(df_genuine_us['id'].unique().shape[0]), random_state=42)\n",
        "\n",
        "X_train = pd.concat([X_train_b, X_train_g])\n",
        "y_train = np.hstack([y_train_b, y_train_g])\n",
        "\n",
        "X_test = pd.concat([X_test_b, X_test_g])\n",
        "y_test = np.hstack([y_test_b, y_test_g])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62ob6vonQivk",
        "colab_type": "text"
      },
      "source": [
        "Drop columns which are made entirely of NaN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSR8Mt_-54TK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nanCols = (~df_tradicionalbot_us.isna()).sum()\n",
        "nanCols = nanCols[nanCols == 0].index\n",
        "\n",
        "X_train = X_train.drop(nanCols, axis=1)\n",
        "X_test = X_test.drop(nanCols, axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56ZhuBYvQ8Tc",
        "colab_type": "text"
      },
      "source": [
        "Define functions to drop/transform columns for train and test sets together:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmDfcTVjOFTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def drop_col(X_train, X_test, col):\n",
        "    X_train.drop(col, axis=1, inplace=True)\n",
        "    X_test.drop(col, axis=1, inplace=True)\n",
        "\n",
        "def transform_bool(X_train, X_test, col):\n",
        "    X_train['has_' + col] = (~X_train[col].isna()) * 1\n",
        "    X_test['has_' + col] = (~X_test[col].isna()) * 1\n",
        "    drop_col(X_train, X_test, col)\n",
        "\n",
        "def transform_bool2(X_train, X_test, col, missing=0):\n",
        "    X_train[col] = (X_train[col] != missing).astype(np.int64)\n",
        "    X_test[col] = (X_test[col] != missing).astype(np.int64)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jneDY8SUOZzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_bool(X_train, X_test, 'url')\n",
        "transform_bool(X_train, X_test, 'location')\n",
        "transform_bool(X_train, X_test, 'description')\n",
        "X_train['geo_enabled'] = X_train['geo_enabled'].fillna(0)\n",
        "X_test['geo_enabled'] = X_test['geo_enabled'].fillna(0)\n",
        "drop_col(X_train, X_test, ['name', 'screen_name', 'statuses_count', 'profile_image_url', 'profile_background_image_url', 'created_at', 'timestamp', 'crawled_at', 'updated'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31n0Gbw1R_rU",
        "colab_type": "text"
      },
      "source": [
        "Load and process tweets data. Drop tweets whose users are not in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_5kwkITw8xp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_user_ids = {id: True for id in X_train['id']}\n",
        "\n",
        "df_tradicionalbot_tw = pd.read_csv(\n",
        "    'datasets_full/traditional_spambots_1/tweets.csv',\n",
        "    usecols=[\"id\",\"text\",\"source\",\"user_id\",\"in_reply_to_user_id\",\"num_hashtags\",\"num_urls\",\"num_mentions\",\"timestamp\"])\n",
        "df_tradicionalbot_tw.fillna({'in_reply_to_screen_name':''}, inplace=True)\n",
        "train_bot_mask = df_tradicionalbot_tw.user_id.apply(lambda id: train_user_ids.get(id, False))\n",
        "df_tradicionalbot_tw_train = df_tradicionalbot_tw[train_bot_mask]\n",
        "df_tradicionalbot_tw_test = df_tradicionalbot_tw[~train_bot_mask]\n",
        "\n",
        "df_genuine_tw = pd.read_csv(\n",
        "    'datasets_full/genuine_accounts.csv/tweets.csv',\n",
        "    header=None, sep=',', quotechar='\"', escapechar='\\\\', na_values=['nan'], keep_default_na=False,\n",
        "    usecols=[0,1,2,3,6,19,20,21,22])\n",
        "df_genuine_tw.columns = df_tradicionalbot_tw.columns\n",
        "train_user_mask = df_genuine_tw.user_id.apply(lambda id: train_user_ids.get(id, False))\n",
        "df_genuine_tw_train = df_genuine_tw[train_user_mask]\n",
        "df_genuine_tw_test = df_genuine_tw[~train_user_mask]\n",
        "\n",
        "tweets_train = pd.concat([df_tradicionalbot_tw_train, df_genuine_tw_train], ignore_index=True)\n",
        "tweets_test = pd.concat([df_tradicionalbot_tw_test, df_genuine_tw_test], ignore_index=True)\n",
        "\n",
        "has_tweets_train = {id:True for id in tweets_train['user_id']}\n",
        "has_tweets_test = {id:True for id in tweets_test['user_id']}\n",
        "\n",
        "X_train_tw_mask = X_train['id'].apply(lambda id: has_tweets_train.get(id, False))\n",
        "X_test_tw_mask = X_test['id'].apply(lambda id: has_tweets_test.get(id, False))\n",
        "\n",
        "X_train = X_train[X_train_tw_mask]\n",
        "X_test = X_test[X_test_tw_mask]\n",
        "\n",
        "y_train = y_train[X_train_tw_mask]\n",
        "y_test = y_test[X_test_tw_mask]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkP4pqxy10dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_bool2(tweets_train, tweets_test, 'in_reply_to_user_id', missing=0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOatWalUSnhL",
        "colab_type": "text"
      },
      "source": [
        "Add average number of tweets that were marked as a reply to another user to the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73GE79Fu8lVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.join(\n",
        "    (tweets_train[['user_id','in_reply_to_user_id']]\n",
        "     .groupby('user_id')['in_reply_to_user_id']\n",
        "     .mean()\n",
        "     .rename('mean_reply_to_user_id')), on='id')\n",
        "X_test = X_test.join(\n",
        "    (tweets_test[['user_id','in_reply_to_user_id']]\n",
        "     .groupby('user_id')['in_reply_to_user_id']\n",
        "     .mean()\n",
        "     .rename('mean_reply_to_user_id')), on='id')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHsfU38sS6kk",
        "colab_type": "text"
      },
      "source": [
        "Perform normalization on the appropriate features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNFW4C8IpWTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scalable_columns = ['followers_count', 'friends_count',\n",
        "       'favourites_count', 'listed_count', 'mean_reply_to_user_id']\n",
        "scaler = MinMaxScaler().fit(X_train[scalable_columns])\n",
        "X_train[scalable_columns] = scaler.transform(X_train[scalable_columns])\n",
        "X_test[scalable_columns] = scaler.transform(X_test[scalable_columns])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR6b-FR2VFFE",
        "colab_type": "text"
      },
      "source": [
        "# Model training and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik4YhUNDVPST",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4uCW9AZUUGy",
        "colab_type": "text"
      },
      "source": [
        "Drop 'id' column, and train Logistic Regression and Random Forest models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6tETE03Nvgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_drop = ['id']\n",
        "logistic_reg_model = LogisticRegression(C=1000000, max_iter=100000).fit(X_train.drop(to_drop, axis=1), y_train)\n",
        "random_for_model = RandomForestClassifier().fit(X_train.drop(to_drop, axis=1), y_train)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyoUYFnLVTKL",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHxRCjul2NCH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "4529a1d5-9d7a-4d23-bcf9-162a994f7115"
      },
      "source": [
        "print(\"Logistic Regression testing accuracy: \", logistic_reg_model.score(X_test.drop(to_drop, axis=1), y_test))\n",
        "print(\"                            precision: \", metrics.precision_score(y_test, logistic_reg_model.predict(X_test.drop(to_drop, axis=1))))\n",
        "print(\"                            recall: \", metrics.recall_score(y_test, logistic_reg_model.predict(X_test.drop(to_drop, axis=1))))\n",
        "print(\"\")\n",
        "print(\"Logistic Regression training accuracy: \", logistic_reg_model.score(X_train.drop(to_drop, axis=1), y_train))\n",
        "print(\"                             precision: \", metrics.precision_score(y_train, logistic_reg_model.predict(X_train.drop(to_drop, axis=1))))\n",
        "print(\"                             recall: \", metrics.recall_score(y_train, logistic_reg_model.predict(X_train.drop(to_drop, axis=1))))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression testing accuracy:  0.9762989972652689\n",
            "                            precision:  0.9516129032258065\n",
            "                            recall:  0.944\n",
            "\n",
            "Logistic Regression training accuracy:  0.9769487412799515\n",
            "                             precision:  0.9457671957671958\n",
            "                             recall:  0.9533333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRikmXsWpJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "f649523e-5556-4424-bc65-ff311a5ff320"
      },
      "source": [
        "print(\"Random Forest testing accuracy: \", random_for_model.score(X_test.drop(to_drop, axis=1), y_test))\n",
        "print(\"                      precision: \", metrics.precision_score(y_test, random_for_model.predict(X_test.drop(to_drop, axis=1))))\n",
        "print(\"                      recall: \", metrics.recall_score(y_test, random_for_model.predict(X_test.drop(to_drop, axis=1))))\n",
        "print(\"\")\n",
        "print(\"Random Forest training accuracy: \", random_for_model.score(X_train.drop(to_drop, axis=1), y_train))\n",
        "print(\"                       precision: \", metrics.precision_score(y_train, random_for_model.predict(X_train.drop(to_drop, axis=1))))\n",
        "print(\"                       recall: \", metrics.recall_score(y_train, random_for_model.predict(X_train.drop(to_drop, axis=1))))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest testing accuracy:  0.9908842297174111\n",
            "                      precision:  0.9838709677419355\n",
            "                      recall:  0.976\n",
            "\n",
            "Random Forest training accuracy:  1.0\n",
            "                       precision:  1.0\n",
            "                       recall:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}